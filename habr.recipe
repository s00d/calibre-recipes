#!/usr/bin/env  python
# -*- coding: utf-8 -*-

##
## Title:        Habrahabr Blogs Recipe
## Contact:      wistful - <wst dot public dot mail at gmail dot com>'
##
## License:      GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html
## Copyright:    wistful - <wst dot public dot mail at gmail dot com>'
##
## Written:      December 2011
## Last Edited:  2011-12-23
##

__license__     = 'GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html'
__copyright__ = '2011 wistful <wst dot public dot mail at gmail dot com>'

import re
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import Tag, NavigableString


'''
http://habrahabr.ru/blogs/
'''


rm_tags = re.compile(r'<[^<]*?>')


def cleanup(soup_tag):
    return rm_tags.sub('', str(soup_tag))


class Habr(BasicNewsRecipe):
    blogs = {'webdev':      'http://habrahabr.ru/blogs/webdev/',
             'javascript':  'http://habrahabr.ru/blogs/javascript/',
             'jQuery':      'http://habrahabr.ru/blogs/jquery/',
             'css':         'http://habrahabr.ru/blogs/css/',
             'python':      'http://habrahabr.ru/blogs/python/',
             'linux':       'http://habrahabr.ru/blogs/linux/',
             'Убунтариум':  'http://habrahabr.ru/blogs/ubuntu/',
             'development': 'http://habrahabr.ru/blogs/development/',
             'programming': 'http://habrahabr.ru/blogs/programming/',
             'Git':         'http://habrahabr.ru/blogs/Git/',
             'web design':  'http://habrahabr.ru/blogs/web_design/'
    }

    masthead_url            = 'http://upload.wikimedia.org/wikipedia/ru/7/7f/Habrahabr_logo.png'

    oldest_article          = 20
    max_articles_per_feed   = 200
    title                   = u'Хабр'
    __author__              = 'wistful'
    description             = u'Блоги с HABRAHABR.RU'
    publisher               = 'habrahabr.ru'
    publication_type        = 'blog'
    category                = 'it, tech, news'
    language                = 'ru'

    no_stylesheets = True
    extra_css = """
        body {font-size: 90%;}
        .content h2 {margin: 0;}
        pre, code, tt { font-size: 55%;
                    letter-spacing: -0.1pt;
                  }
        .comment {font-size: 0.5em;}
        """
    direction             = 'ltr'

    html2lrf_options = [
        '--comment'  , description
        , '--category' , category
        , '--publisher', publisher
    ]

    html2epub_options = 'publisher="' + publisher + '"\ncomments="' + description + '"\ntags="' + category

    keep_only_tags = [dict(name='div', attrs={'class':'post'}), dict(name='div', attrs={'class':'comments_list '})]

    def parse_index(self):
        feeds = []
        for blog_name, blog_url in self.blogs.items():
            doc = self.index_to_soup(blog_url)
            articles = []
            for post in doc.findAll('div', attrs={'class':'post'}):
                title_link = post.find('a', attrs={'class': 'post_title'})
                title = cleanup(title_link)
                description = post.find('div', attrs={'class': 'content'})
                [item.extract() for item in description.findAll('img')]
                [item.extract() for item in description.findAll('div', attrs={'class': 'habracut'})]
                articles.append({'title': title, 'url': title_link['href'], 'content': '', 'date': '', 'description': str(description)})
            feeds.append((blog_name, articles))
        return feeds
