#!/usr/bin/env  python
# -*- coding: utf-8 -*-

##
## Title:        Inoblogger Recipe
## Contact:      wistful - <wst dot public dot mail at gmail dot com>'
##
## License:      GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html
## Copyright:    wistful - <wst dot public dot mail at gmail dot com>'
##
## Written:      December 2011
## Last Edited:  2011-12-18
##

__license__     = 'GNU General Public License v3 - http://www.gnu.org/copyleft/gpl.html'
__copyright__ = '2011 wistful <wst dot public dot mail at gmail dot com>'


import re
from calibre.web.feeds.news import BasicNewsRecipe
from calibre.ebooks.BeautifulSoup import Tag, NavigableString

'''
inoblogger.ru
'''

rm_tags = re.compile(r'<[^<]*?>')


def cleanup(soup_tag):
    return rm_tags.sub('', str(soup_tag))


class Inoblogger(BasicNewsRecipe):

    oldest_article          = 7
    max_articles_per_feed   = 100
    masthead_url            = 'http://inoblogger.ru/wp-content/themes/inove/img/header.png'
    title                   = 'Inoblogger'
    __author__              = 'wistful'
    description             = u'Иноблоггер - Единый центр экспертизы'
    publisher               = 'Inoblogger.ru'
    publication_type        = 'blog'
    category                = 'news, blog'
    INDEX = 'http://inoblogger.ru/'
    language                = 'ru'
    lang = 'ru'

    auto_cleanup_keep = '//a[@class="title"]'
    keep_only_tags = [dict(name='div', attrs={'class': re.compile("\s*post\s*", re.IGNORECASE)})]
    remove_tags_after = [dict(name='div', attrs={'class': re.compile("\s*content\s*", re.IGNORECASE)})]
    no_stylesheets = True
    direction             = 'ltr'

    html2lrf_options = [
        '--comment'  , description
        , '--category' , category
        , '--publisher', publisher
    ]

    html2epub_options = 'publisher="' + publisher + '"\ncomments="' + description + '"\ntags="' + category

    def parse_index(self):
        doc = self.index_to_soup(self.INDEX)
        feeds = []
        articles = []
        for post in doc.findAll('div', attrs={'class':'post'}):
            more_link = post.find('a', attrs={'class': 'title'})
            title = cleanup(more_link)
            content = ''
            link = ''
            description = post.find(attrs={'class': 'content'})
            [item.extract() for item in description.findAll() if item.name != 'p']
            if more_link:
                link = more_link['href']
            else:
                content = post.find('div', attrs={'class': 'content'}).text
            articles.append({'title': title, 'url': link, 'content': content, 'date': '', 'description': str(description)})
        feeds.append(('articles', articles))
        return feeds
